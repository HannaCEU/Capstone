# Load required packages
library(readxl)
library(tidyverse)
library(dplyr)
library(tidyr)
library(arsenal)
library(knitr)
library(modelsummary)
install.packages("kableExtra")
install.packages("wbstats")
install.packages("arsenal")

## Section 1. Download raw data
# Read the Excel file
Use the relevant path or direct download from: https://dataunodc.un.org/sites/dataunodc.un.org/files/data_glotip.xlsx

## Section 2. Data Cleaning and Transformation
# Select the relevant columns
data_subset <- select(data, Iso3_code, Country, Indicator, Dimension, Category, Sex, Age, Year, txtVALUE)

# Check class of columns and any mistakes, especially Italy(!)
class(data_subset$txtVALUE)
class(data_subset$Year)
class(data_subset$Indicator)
class(data_subset$Age)
class(data_subset$Sex)
unique(data_subset$Year)

# Filter for the region specific countries and years
countries <- c("Albania", "Andorra", "Armenia", "Austria", "Azerbaijan", "Belarus", "Belgium", "Bosnia and Herzegovina", "Bulgaria", "Canada", "Croatia", "Cyprus", "Czechia", "Denmark", "Estonia", "Finland", "France", "Georgia", "Germany", "Greece", "Holy See", "Hungary", "Iceland", "Ireland", "Italy", "Kazakhstan", "Kyrgyzstan", "Latvia", "Liechtenstein", "Lithuania", "Luxembourg", "Malta", "Republic of Moldova", "Monaco", "Mongolia", "Montenegro", "Netherlands", "North Macedonia", "Norway", "Poland", "Portugal", "Romania", "Russian Federation", "San Marino", "Serbia", "Slovakia", "Slovenia", "Spain", "Sweden", "Switzerland", "Tajikistan", "TÃ¼rkiye", "Turkmenistan", "Ukraine", "United Kingdom of Great Britain and Northern Ireland", "United States of America", "Uzbekistan")
years <- c(2017, 2018, 2019, 2020, 2021)
data_subset <- filter(data_subset, Country %in% countries, Year %in% years)

# Explore the dataframe
str(data_subset)
unique(data_subset$Country)
unique(data_subset$Indicator)
unique(data_subset$Dimension)
unique(data_subset$Sex)

# Inquiry on the total numbers of victims and perpetrators
sum(data_subset$Indicator == "Detected trafficking victims")
sum(data_subset$Indicator == "Persons prosecuted")
sum(data_subset$Indicator == "Persons convicted")

# Factorize columns on indicator, dimension and sex
data_subset[, c("Iso3_code", "Country", "Indicator", "Dimension", "Sex")] <- lapply(data_subset[, c("Iso3_code", "Country", "Indicator", "Dimension", "Sex")], as.factor)

# Check class
class(data_subset$Iso3_code)

## Further Data cleaning 
# I can see that some states have been reporting with delimiters(e.g.Italy!), so I need to clean out their submissions to a processable format. 
lines_with_commas <- which(grepl(",", data_subset$txtVALUE))
print(lines_with_commas)

# Replace commas on the identified lines
data_subset$txtVALUE[lines_with_commas] <- gsub(",", "", data_subset$txtVALUE[lines_with_commas])

# Check again 
lines_with_commas <- which(grepl(",", data_subset$txtVALUE))
print(lines_with_commas)

## Data Transformation
# I can see that there are quite a few countries reporting "<5" values. However, there are two types of those countries: some not reporting and some are in fact <5. n consultation with Create exception for the countries which do not submit reports and neither have cases according to the field experts
exception_condition <- data_subset$Country %in% c("Andorra", "Iceland", "Holy See", "Liechtenstein", "Monaco", "San Marino")

# Replace values with exceptions as 0 and the rest as 2
data_subset$txtVALUE[data_subset$txtVALUE == "<5" & !exception_condition] <- 2
data_subset$txtVALUE[exception_condition] <- 0

## Data cleaning now again to rename and convert the column to numeric
data_subset$Count <- as.numeric(data_subset$txtVALUE)
sum(is.na(data_subset$Count))

# Drop txtValue
data_subset$txtVALUE <- NULL

## Write out data in long format

# Write out data with the total count of victims, prosecutions and convictions
data_total <- filter(data_subset, data_subset$Dimension == "Total", data_subset$Age == "Total", data_subset$Sex == "Total")

# The domain expert suggested to drop observations on "Persons brought into formal contact" and "Offences of trafficking in persons" as irrelevant for the analysis.
# But then in data analysis discovered that some countries do not report on prosecutions/convictions, but do report on offences, e.g. Italy, Portugal, so had to bring it back. Correct code is below.
data_total <- subset(data_total, !(Indicator %in% c("Persons brought into formal contact")))

data_total <- data_total[, c("Iso3_code", "Country", "Indicator", "Year", "Count")]

# Write out the abridged cleaned data in the long format for later use in the monitoring tool
write.csv(data_total, "file_2.csv", row.names = FALSE)

# Write out all clean disintegrated data in the long format
write.csv(data_subset, "file_extended_2.csv", row.names = FALSE)

## Section 3. Normalisation of metrics on victims

# As in the countries number of population greatly varies, it will be necessary to normalise the data during analysis. It is already clear that only victims are consistently reported and can be meaningfully used for normalisation. 
## With wbstats package I can download data on population from the World Bank directly and in a tidy format, i.e. wide, without na, with values as numeric. So I decide to use this clean dataset for my analysis.
df0 <- wbstats::wb_data("SP.POP.TOTL", country = "countries_only", return_wide = FALSE, mrv = 1)

#The population data is from 2021 and this satisfies my needs as my dataset is 2017-2021
#I only need to harmonise the names of the columns for a join.
#Renaming and extracting columns 
df0 <- df0 %>%
  rename(Iso3_code = iso3c, Population = value) %>%
  select(Iso3_code, Population)

# Join data_total with population by WB based on the Country column
by_mln_population <- left_join(data_total, df0, by = "Iso3_code")

#To normalise the data, I create the "count_by_mln" column
by_mln_population$Count_by_mln <- (by_mln_population$Count / by_mln_population$Population) * 1e6

# Remove and round up numbers after decimal point in count_by_mln column
by_mln_population$Count_by_mln <- floor(by_mln_population$Count_by_mln)

# Filter the dataframe by Year = 2020
filtered_df <- by_mln_population[by_mln_population$Year == 2020 & by_mln_population$Indicator == "Detected trafficking victims", ]

# Exploring the normalised and total count data
# Sort the filtered dataframe by count_by_mln column in descending order
filtered_df <- filtered_df[order(filtered_df$Count_by_mln, decreasing = TRUE), ]

# Select the top 5 rows with the highest number of "Detected trafficking victims" by mln population in 2021 count_by_mln values
top_5_rows <- head(sorted_df, 5)

# Identify the highest total number of "Detected trafficking victims" by count
df_total <- data_total[data_total$Year == 2020 & data_total$Indicator == "Detected trafficking victims", ]

# Sort the filtered dataframe by count_by_mln column in descending order
df_total <- df_total[order(df_total$Count, decreasing = TRUE), ]

# Select the top 5 rows with the highest number of "Detected trafficking victims" by mln population in 2021 count_by_mln values
top_total_5_rows <- head(df_total, 5)

#write out the csv file for the later use in Tableau
write.csv(by_mln_population, "by_mln_population_2.csv", row.names = FALSE)

## Section 4. Descriptive Statistics on data total in Year 2020

#Filter for the year and look into the most recently available data
wide_data <- data_total %>%
  filter(Year == 2020) %>%
  pivot_wider(id_cols = Country, names_from = Indicator, values_from = Count)

sum(is.na(wide_data$"Persons prosecuted"))

wide_data <- wide_data %>%
  rename(
    victims = "Detected trafficking victims",
    prosecutions = "Persons prosecuted",
    convictions = "Persons convicted",
    offences = "Offences of trafficking in persons"
  )

# I know that apart from victims there will be NAs due to absence of reporting, so I have to account for this in my code.
P95 <- function(x){quantile(x,0.95,na.rm=T)}
P05 <- function(x){quantile(x,0.05,na.rm=T)}

summary_stats <- datasummary( (`Detected trafficking victims` = floor(victims )) + 
               (`Persons prosecuted` = floor(prosecutions)) +
               (`Persons convicted` = floor(convictions)) +
               (`Offences of trafficking in persons` = floor(offences)) ~
               Mean + Median + SD + Min + Max + P05 + P95, 
               data = wide_data ,
               title = "Descriptive statistics")

print(summary_stats)

